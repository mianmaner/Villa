Content,EventTemplate
"Cannot assign container Container: [ContainerId: container_1445062781478_0018_01_000013, NodeId: MININT-75DGDAM1.fareast.corp.microsoft.com:51951, NodeHttpAddress: MININT-75DGDAM1.fareast.corp.microsoft.com:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 10.86.165.66:51951 }, ] for a map as either container memory less than required <memory:1024, vCores:1> or no pending map tasks - maps.isEmpty=true","Cannot assign container Container: [ContainerId: {container_id}, NodeId: {node_id}, NodeHttpAddress: {http_address}, Resource: {memory_info}, Priority: {number}, Token: {token_info}, ] for a map as either container memory less than required {memory_info} or no pending map tasks - maps.isEmpty={bool}"
Task: attempt_1445144423722_0020_m_000002_0 - exited : java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: <url id="cueu6l4tr22gd9e6rsd0" type="url" status="failed" title="" wc="0">http://wiki.apache.org/hadoop/NoRouteToHost,Task:</url>  {task_id} - exited : java.net.NoRouteToHostException: No Route to Host from {ip_address} to {ip_address} failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: {website_url}
"Could not obtain BP-1347369012-10.190.173.170-1444972147527:blk_1073741828_1004 from any node: java.io.IOException: No live nodes contain block BP-1347369012-10.190.173.170-1444972147527:blk_1073741828_1004 after checking nodes = [172.22.149.145:50010, 10.190.173.170:50010], ignoredNodes = null No live nodes contain current block Block locations: 172.22.149.145:50010 10.190.173.170:50010 Dead nodes: 10.190.173.170:50010 172.22.149.145:50010. Will get new block locations from namenode and retry","Could not obtain {block_name} from any node: {exception} No live nodes contain block {block_name} after checking nodes = {ip_list}, ignoredNodes = {node_info} No live nodes contain current block Block locations: {ip_list} Dead nodes: {ip_list}. Will get new block locations from namenode and retry"
"completedMapPercent 0.53846157 totalResourceLimit:<memory:16384, vCores:-4> finalMapResourceLimit:<memory:8192, vCores:-2> finalReduceResourceLimit:<memory:8192, vCores:-2> netScheduledMapResource:<memory:12288, vCores:12> netScheduledReduceResource:<memory:0, vCores:0>","completedMapPercent {number} totalResourceLimit:<memory:{number}, vCores:{number} finalMapResourceLimit:<memory:{number}, vCores:{number} finalReduceResourceLimit:<memory:{number}, vCores:{number} netScheduledMapResource:<memory:{number}, vCores:{number} netScheduledReduceResource:<memory:{number}, vCores:{number}"
Before Scheduling: PendingReds:1 ScheduledMaps:13 ScheduledReds:0 AssignedMaps:0 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:0 ContRel:0 HostLocal:0 RackLocal:0,Before Scheduling: PendingReds:{number} ScheduledMaps:{number} ScheduledReds:{number} AssignedMaps:{number} AssignedReds:{number} CompletedMaps:{number} CompletedReds:{number} ContAlloc:{number} ContRel:{number} HostLocal:{number} RackLocal:{number}
Socket Reader #1 for port 32070: readAndProcess from client 10.86.164.9 threw exception [java.io.IOException: An existing connection was forcibly closed by the remote host],Socket Reader {index} for port {number} readAndProcess from client {ip} threw exception [java.io.IOException: An existing connection was forcibly closed by the remote host]
"Slow ReadProcessor read fields took 65020ms (threshold=30000ms); ack: seqno: -2 status: SUCCESS status: ERROR downstreamAckTimeNanos: 0, targets: [10.86.169.121:50010, 10.190.173.170:50010]","Slow ReadProcessor read fields took {time} (threshold={time}); ack: seqno: {number} status: {status_info} status: {status_info} downstreamAckTimeNanos: {number}, targets: [{ip}, {ip}]"
Not uberizing job_1445087491445_0005 because: not enabled; too many maps; too much input;,Not uberizing {job_id} because: not enabled; too many maps; too much input;
TaskAttempt: [attempt_1445087491445_0005_m_000009_0] using containerId: [container_1445087491445_0005_01_000009 on NM: [04DN8IQ.fareast.corp.microsoft.com:55452],TaskAttempt: [{task_id}] using containerId: [{container_id} on NM: [{node_id}]
"Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: 5 cluster_timestamp: 1445087491445 } attemptId: 1 } keyId: -1547346236)","Kind: {kind_info}, Service: {service_info}, Ident: ({ident_info})"
"Retrying connect to server: minint-75dgdam1.fareast.corp.microsoft.com/10.86.165.66:53419. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)","Retrying connect to server: {server_ip}. Already tried {number} time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries={number}, sleepTime={number} MILLISECONDS)"
(RESET) equator 44657541 kv 11164380(44657520) kvi 8542952(34171808),(RESET) equator {number} kv {number}({number}) kvi {number}({number})
attempt_1445087491445_0005_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events,{task_id} Thread started: EventFetcher for fetching Map Completion Events
DefaultSpeculator.addSpeculativeAttempt -- we are speculating task_1445087491445_0005_m_000011,DefaultSpeculator.addSpeculativeAttempt -- we are speculating {task_id}
Communication exception: java.net.ConnectException: Call From MSRA-SA-39/172.22.149.145 to minint-fnanli5.fareast.corp.microsoft.com:49594 failed on connection exception: java.net.ConnectException: Connection timed out: no further information; For more details see: <url id="cueu6l4tr22gd9e6rse0" type="url" status="failed" title="" wc="0">http://wiki.apache.org/hadoop/ConnectionRefused,Communication</url>  exception: java.net.ConnectException: Call From {ip_address} to {ip_address} failed on connection exception: java.net.ConnectException: Connection timed out: no further information; For more details see: {website_url}
"Down to the last merge-pass, with 7 segments left of total size: 228411640 bytes","Down to the last merge-pass, with {number} segments left of total size: {number} bytes"
finalMerge called with 0 in-memory map-outputs and 13 on-disk map-outputs,finalMerge called with {number} in-memory map-outputs and {number} on-disk map-outputs
Service JobHistoryEventHandler failed in state STOPPED; cause: org.apache.avro.AvroTypeException: Attempt to process a enum when a union was expected,Service {class_name} failed in state {status_info}; cause: {class_name}: Attempt to process a enum when a union was expected
"session.id is deprecated. Instead, use dfs.metrics.session-id","{function} is deprecated. Instead, use {function}"
"MergerManager: memoryLimit=130652568, maxSingleShuffleLimit=32663142, mergeThreshold=86230696, ioSortFactor=10, memToMemMergeOutputsThreshold=10","MergerManager: memoryLimit={number}, maxSingleShuffleLimit={number}, mergeThreshold={number}, ioSortFactor={number}, memToMemMergeOutputsThreshold={number}"
fetcher#2 about to shuffle output of map attempt_1445087491445_0005_m_000000_0 decomp: 227948846 len: 227948850 to DISK,fetcher#{number} about to shuffle output of map {task_id}: {number} len: {number} to DISK
"MRAppMaster launching normal, non-uberized, multi-container job job_1445087491445_0005","MRAppMaster launching normal, non-uberized, multi-container job {job_id}"
Web app /mapreduce started at 32067,Web app {app_name} started at {port}
We launched 1 speculations. Sleeping 15000 milliseconds,We launched {number} speculations. Sleeping {number} milliseconds
bufstart = 0; bufend = 34171787; bufvoid = 104857600,bufstart = {number}; bufend = {number}; bufvoid = {number}
"DFS chooseDataNode: got # 1 IOException, will wait for 723.7852941897946 msec","DFS chooseDataNode: got # {number} IOException, will wait for {time} msec"
Diagnostics report from attempt_1445144423722_0020_m_000006_0: cleanup failed for container container_1445144423722_0020_01_000008 : java.lang.IllegalArgumentException: java.net.UnknownHostException: MSRA-SA-41.fareast.corp.microsoft.com,Diagnostics report from {task_id}: cleanup failed for container {container_id} : java.lang.IllegalArgumentException: java.net.UnknownHostException: {ip_address}
Input size for job job_1445087491445_0005 = 1751822336. Number of splits = 13,Input size for job {job_id} = {number}. Number of splits = {number}
Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context mapreduce,Added filter {filter_name} (class={class_name}) to context {context_name}
"getResources() for application_1445087491445_0005: ask=7 release= 0 newContainers=0 finishedContainers=0 resourcelimit=<memory:13312, vCores:-7> knownNMs=3","getResources() for {app_id}: ask={number} release= {number} newContainers={number} finishedContainers={number} resourcelimit=<memory:{number}, vCores:{number}> knownNMs={number}"
JVM with ID : jvm_1445087491445_0005_m_000002 asked for a task,JVM with ID : {jvm_id} asked for a task
Reduce slow start threshold reached. Scheduling reduces,Reduce slow start threshold reached. Scheduling reduces
