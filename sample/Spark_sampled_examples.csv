Content,EventTemplate
"Prepared Local resources Map(spark.jar -> resource { scheme: ""hdfs"" host: ""10.10.34.11"" port: 9000 file: ""/user/curi/.sparkStaging/application_1485248649253_0020/spark-assembly-1.6.0-hadoop2.2.0.jar"" } size: 109525492 timestamp: 1489498812773 type: FILE visibility: PRIVATE, pyspark.zip -> resource { scheme: ""hdfs"" host: ""10.10.34.11"" port: 9000 file: ""/user/curi/.sparkStaging/application_1485248649253_0020/pyspark.zip"" } size: 355358 timestamp: 1489498812856 type: FILE visibility: PRIVATE, py4j-0.9-src.zip -> resource { scheme: ""hdfs"" host: ""10.10.34.11"" port: 9000 file: ""/user/curi/.sparkStaging/application_1485248649253_0020/py4j-0.9-src.zip"" } size: 44846 timestamp: 1489498812874 type: FILE visibility: PRIVATE)","Prepared Local resources Map(spark.jar -> resource { scheme: {scheme} host: {ip} port: {number} file: {file_path} } size: {number} timestamp: {number} type: {type} visibility: {visibility}, pyspark.zip -> resource { scheme: {scheme} host: {ip} port: {number} file: {file_path} } size: {number} timestamp: {number} type: {type} visibility: {visibility}, py4j-{number}-src.zip -> resource { scheme: {scheme} host: {ip} port: {number} file: {file_path} } size: {number} timestamp: {number} type: {type} visibility: {visibility})"
"Lost task 0.1 in stage 4.0 (TID 12, mesos-slave-08): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container marked as failed: container_1485248649253_0076_02_000002 on host: mesos-slave-08. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143","Lost task {number} in stage {number} (TID {number}, {mesos_slave_id}): ExecutorLostFailure (executor {number} exited caused by one of the running tasks) Reason: Container marked as failed: {container_id} on host: {mesos_slave_id}. Exit status: {number}. Diagnostics: {diagnostics}. Exit code is {number}"
"SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(21, mesos-slave-13, 57719),broadcast_5_piece323,StorageLevel(false, true, false, false, 1),4194304,0,0))",SparkListenerBus has already stopped! Dropping event {event_info}
Unregistering ApplicationMaster with FAILED (diag message: Uncaught exception: org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply in 120 seconds. This timeout is controlled by spark.rpc.askTimeout),Unregistering ApplicationMaster with {error_info}
Container killed by YARN for exceeding memory limits. 54.7 GB of 46.2 GB virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead,Container killed by YARN for exceeding memory limits. {memory_size} of {memory_size} virtual memory used. Consider boosting {function}
Marking ResultStage 5 (collect at pnmf4.py:377) as failed due to a fetch failure from ShuffleMapStage 4 (reduceByKey at pnmf4.py:371),Marking ResultStage {number} (collect at {code_pos}) as failed due to a fetch failure from ShuffleMapStage {number} ({event} at {code_pos})
"Registering block manager mesos-master-1:48869 with 14.2 GB RAM, BlockManagerId(6, mesos-master-1, 48869)","Registering block manager {mesos_master_id} with {memory_size} RAM, BlockManagerId({number}, {mesos_master_id}, {number})"
"SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(yarn, curi); users with modify permissions: Set(yarn, curi)","SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set({process}, {process}); users with modify permissions: Set({process}, {process})"
"Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.7 KB, free 3.7 KB)","Block {block_name} stored as bytes in memory (estimated size {memory_size}, free {memory_size})"
"Final app status: FAILED, exitCode: 11, (reason: Max number of executor failures (4) reached)","Final app status: {status}, exitCode: {number}, (reason: {reason})"
Driver terminated or disconnected! Shutting down. 10.10.34.11:51096,Driver terminated or disconnected! Shutting down. {mesos_master_id}
"Started progress reporter thread with (heartbeat : 3000, initial allocation : 200) intervals","Started progress reporter thread with (heartbeat : {number}, initial allocation : {number}) intervals"
Getting 2 non-empty blocks out of 2 blocks,Getting {number} non-empty blocks out of {number} blocks
"Submitting ResultStage 6 (MapPartitionsRDD[15] at saveAsTextFile at NativeMethodAccessorImpl.java:-2), which has no missing parents","Submitting ResultStage {number} ({event} at {code_pos}), which has no missing parents"
"Lost task 25.0 in stage 1.0 (TID 27, mesos-slave-27): org.apache.spark.api.python.PythonException: Traceback (most recent call last):","Lost task {number} in stage {number} (TID {number}, {mesos_slave_id}): org.apache.spark.api.python.PythonException: Traceback (most recent call last):"
Connection to mesos-master-1/10.10.34.11:51096 has been quiet for 120000 ms while there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout if this is wrong,Connection to {ip} has been quiet for {number} ms while there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout if this is wrong
"Will request 6 executor containers, each with 8 cores and 22528 MB memory including 2048 MB overhead","Will request {number} executor containers, each with {number} cores and {number} MB memory including {number} MB overhead"
"Completed container container_1485248649253_0037_01_000002 on host: mesos-slave-16 (state: COMPLETE, exit status: -100)","Completed container {container_id} on host: {mesos_slave_id} (state: {status}, exit status: {number})"
"Add WebUI Filter. AddWebUIFilter(org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter,Map(PROXY_HOSTS -> mesos-master-1, PROXY_URI_BASES -> http://mesos-master-1:8088/proxy/application_1485248649253_0166),/proxy/application_1485248649253_0166)","Add WebUI Filter. AddWebUIFilter({function},Map(PROXY_HOSTS -> {mesos_master_id}, PROXY_URI_BASES -> {website_url}),{file_path})"
"[Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker-2,5,main]","[Container in shutdown] Uncaught exception in thread Thread[Executor task launch {worker_id},{number},{function}]"
"mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id","{function} is deprecated. Instead, use {function}"
Incomplete task interrupted: Attempting to kill Python Worker,Incomplete task interrupted: Attempting to kill Python Worker
"Error sending result RpcResponse{requestId=8054183328166237564, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=274 cap=274]}} to mesos-slave-05/10.10.34.15:34469; closing connection","Error sending result RpcResponse{requestId={request_id}, body={buffer_info}} to {ip}; closing connection"
"Registered signal handlers for [TERM, HUP, INT]",Registered signal handlers for {signal_list}
"Launching ExecutorRunnable. driverUrl: spark://CoarseGrainedScheduler@10.10.34.23:47891, executorHostname: mesos-slave-19","Launching ExecutorRunnable. driverUrl: {address_info}, executorHostname: {mesos_slave_id}"
"ensureFreeSpace(1097) called with curMem=0, maxMem=556038881","ensureFreeSpace({number}) called with curMem={number}, maxMem={number}"
"Lost task 1.0 in stage 5.0 (TID 9, mesos-slave-08): java.lang.OutOfMemoryError: Requested array size exceeds VM limit","Lost task {number} in stage {number} (TID {number}, {mesos_slave_id}): java.lang.OutOfMemoryError: Requested array size exceeds VM limit"
ApplicationAttemptId: appattempt_1485248649253_0020_000002,ApplicationAttemptId: {attempt_id}
"Container request (host: Any, capability: <memory:22528, vCores:8>)","Container request (host: {host_info}, capability: <memory:{number}, vCores:{number}>)"
Remote daemon shut down; proceeding with flushing remote transports,Remote daemon shut down; proceeding with flushing remote transports
RECEIVED SIGNAL 15: SIGTERM,RECEIVED SIGNAL {number}: SIGTERM
Stage 1 contains a task of very large size (1181 KB). The maximum recommended task size is 100 KB,Stage {number} contains a task of very large size ({number} KB). The maximum recommended task size is {number} KB
